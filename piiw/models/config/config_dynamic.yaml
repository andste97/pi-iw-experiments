model:
  conv1_in_channels: 3
  conv1_out_channels: 16 # also conv1 out_channels
  conv1_kernel_size: 8
  conv1_stride: 4

  conv2_out_channels: 32
  conv2_kernel_size: 4
  conv2_stride: 2

  fc1_in_features: 2592 # = 32*9*9
  fc1_out_features: 256 # also output layer in_features
  # num_logits: 5 # This value needs to be set dynamically as it depends on the
                  # size of the environment action space. For gridenvs: 5
  add_value: False # Instead of a policy this will output the action value
  output_features: True # set this to true to add dynamic features to model output

plan:
  interactions_budget: 50
  width: 1  # if we use width 1 here, the planner fails. This is a width 2 problem so this is expected.
  discount_factor: 0.99
  cache_subtree: True

train:
  env_id: "GE_MazeKeyDoor-v2"
  seed: 0
  batch_size: 32
  episode_length: 200 # always 200 for gridenvs
  learning_rate: 0.0007
  replay_capacity: 1000
  total_interaction_budget: 1000000
  l2_reg_factor: 0.001
  clip_grad_norm: 40
  rmsprop_alpha: 0.99 # same as rho in tf
  rmsprop_epsilon: 0.1
  add_returns: False
  experience_keys: ["observations", "target_policy"] # can also add "returns" here